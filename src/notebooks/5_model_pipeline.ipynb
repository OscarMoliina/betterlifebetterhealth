{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/oscarmolina/.venv/bda/lib/python3.10/site-packages (from xgboost) (1.13.0)\n",
      "Requirement already satisfied: numpy in /home/oscarmolina/.venv/bda/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install scikit-learn\n",
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import duckdb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/24 20:40:26 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 10.192.99.165 instead (on interface wlp0s20f3)\n",
      "24/04/24 20:40:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/04/24 20:40:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Preprocessing\") \\\n",
    "    .config(\"spark.jars\", \"../utils/duckdb.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:duckdb:../../data/db/exploitation_zone.db\") \\\n",
    "    .option(\"driver\", \"org.duckdb.DuckDBDriver\") \\\n",
    "    .option(\"dbtable\", \"join_table\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Year', 'Area_Km2', 'CBR', 'CDR', 'Deaths', 'E0', 'Medage',\n",
       "       'MR0_4', 'Pop_Dens', 'GSCA', 'Schizophrenia (%)',\n",
       "       'Bipolar disorder (%)', 'Eating disorders (%)', 'Anxiety disorders (%)',\n",
       "       'Drug use disorders (%)', 'Depression (%)', 'Alcohol use disorders (%)',\n",
       "       'Total population', 'Population density, pers per sq km',\n",
       "       'Total population, male (%)', 'Total population, female (%)',\n",
       "       'Mean age of women at birth of first child',\n",
       "       'Women in the Labour Force, Percent of corresponding total for both sexes',\n",
       "       'Female tertiary students, percent of total',\n",
       "       'Female legislators, senior officials and managers, percent of total',\n",
       "       'Female professionals, percent of total for both sexes',\n",
       "       'Female clerks, percent of total for both sexes',\n",
       "       'Female craft and related workers, percent of total for both sexes',\n",
       "       'Female plant and machine operators and assemblers, percent of total for both sexes',\n",
       "       'Female members of parliament, percent of total',\n",
       "       'Total employment, growth rate', 'Unemployment rate',\n",
       "       'Youth unemployment rate',\n",
       "       'GDP at current prices and PPPs, millions of US$',\n",
       "       'GDP per capita at current prices and PPPs, US$',\n",
       "       'Final consumption expenditure per capita, US Dollars, current PPPs',\n",
       "       'Purchasing power parity (PPP), NCU per US$',\n",
       "       'Consumer price index, growth rate',\n",
       "       'Export of goods and services, per cent of GDP',\n",
       "       'Import of goods and services, per cent of GDP',\n",
       "       'External balance on goods and services, per cent of GDP',\n",
       "       'GDP: in agriculture etc (ISIC4 A), output approach, per cent share of GVA',\n",
       "       'GDP: in industry etc (ISIC4 B-E), output approach, per cent share of GVA',\n",
       "       'GDP: in construction (ISIC4 F), output approach, per cent share of GVA',\n",
       "       'GDP: in trade, hospitality, transport and communication (ISIC4 G-J), output approach, per cent share of GVA',\n",
       "       'GDP: in finance and business services (ISIC4 K-N), output approach, per cent share of GVA',\n",
       "       'GDP: in public administration, education and health (ISIC4 O-Q), output approach, per cent share of GVA',\n",
       "       'GDP: in other service activities (ISIC4 R-U), output approach, per cent share of GVA',\n",
       "       'Population aged 0-14', 'Population aged 15-64', 'Population aged 64+',\n",
       "       'Life expectancy at birth', 'Life expectancy at age 65',\n",
       "       'Economic activity rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparativa Dataset Simple vs. Dataset Mitxe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/24 20:40:49 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df = data.toPandas()\n",
    "\n",
    "y = df['Depression (%)']\n",
    "X1 = df[['Schizophrenia (%)', 'Bipolar disorder (%)', 'Eating disorders (%)', \n",
    "         'Anxiety disorders (%)', 'Drug use disorders (%)', 'Alcohol use disorders (%)']]\n",
    "X2 = df.drop(['Country', 'Year', 'Depression (%)'], axis=1)\n",
    "\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=2003)\n",
    "X2_train, X2_test = train_test_split(X2, test_size=0.2, random_state=2003)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1_train_scaled = scaler.fit_transform(X1_train)\n",
    "X1_test_scaled = scaler.transform(X1_test)\n",
    "X2_train_scaled = scaler.fit_transform(X2_train)\n",
    "X2_test_scaled = scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE para el modelo con solo datos de enfermedades: 0.003019290312440158\n",
      "MSE para el modelo con todas las columnas: 0.005844207276130293\n"
     ]
    }
   ],
   "source": [
    "svm_model1 = SVR()\n",
    "svm_model2 = SVR()\n",
    "svm_model1.fit(X1_train_scaled, y_train)\n",
    "svm_model2.fit(X2_train_scaled, y_train)\n",
    "\n",
    "# joblib.dump(scaler, 'scaler1.pkl')\n",
    "# joblib.dump(svm_model1, 'svm_model1.pkl')\n",
    "# joblib.dump(svm_model2, 'svm_model2.pkl')\n",
    "\n",
    "y_pred1 = svm_model1.predict(X1_test_scaled)\n",
    "y_pred2 = svm_model2.predict(X2_test_scaled)\n",
    "mse1 = mean_squared_error(y_test, y_pred1)\n",
    "mse2 = mean_squared_error(y_test, y_pred2)\n",
    "\n",
    "print(\"MSE para el modelo con solo datos de enfermedades:\", mse1)\n",
    "print(\"MSE para el modelo con todas las columnas:\", mse2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pipeline - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pyspark.sql import DataFrame\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "class ModelPipeline:\n",
    "    def __init__(self, data: DataFrame, objective:str, model_type='SVM', model=None, scaler=None) -> None:\n",
    "        self.data = data\n",
    "        self.objective = objective\n",
    "        self.model_type = model_type\n",
    "        self.model = model\n",
    "        self.scaler = scaler if scaler is not None else StandardScaler()\n",
    "\n",
    "    def __train_model(self):\n",
    "        df = self.data.toPandas()\n",
    "        y = df[self.objective]\n",
    "        X = df.drop(['Country', 'Year', self.objective], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2003)\n",
    "        \n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        if self.model_type == 'SVM':\n",
    "            self.model = SVR()\n",
    "        elif self.model_type == 'RF':\n",
    "            self.model = RandomForestRegressor()\n",
    "        elif self.model_type == 'XGB':\n",
    "            self.model = XGBRegressor(objective='reg:squarederror')\n",
    "        \n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        y_pred = self.model.predict(X_test_scaled)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        joblib.dump(self.model, f'{self.model_type}_model.pkl')\n",
    "        joblib.dump(self.scaler, 'scaler.pkl')\n",
    "        \n",
    "        return self.model, self.scaler, None, mse\n",
    "\n",
    "    def __make_predictions(self):\n",
    "        df = self.data.toPandas()\n",
    "        X = df.drop(['Country', 'Year', self.objective], axis=1)\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        y_pred = self.model.predict(X_scaled)\n",
    "        \n",
    "        return self.model, self.scaler, y_pred, None\n",
    "\n",
    "    def predict(self):\n",
    "        if self.model is None or isinstance(self.model, str) and not self.model.endswith('.pkl'):\n",
    "            return self.__train_model()\n",
    "        else:\n",
    "            self.model = joblib.load(self.model) if isinstance(self.model, str) else self.model\n",
    "            self.scaler = joblib.load(self.scaler) if isinstance(self.scaler, str) else self.scaler\n",
    "            return self.__make_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemples d'Ús"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline = ModelPipeline(data=data, objective='Depression (%)', model_type='XGB', scaler=None, model=None)\n",
    "model, scaler, predictions, mse = pipline.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...)\n",
      "StandardScaler()\n",
      "None\n",
      "6.929342554497845e-05\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(scaler)\n",
    "print(predictions)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline = ModelPipeline(data=data, objective='Depression (%)',model_type='SVM')\n",
    "model, scaler, predictions, mse = pipline.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR()\n",
      "StandardScaler()\n",
      "None\n",
      "0.005844207276130293\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(scaler)\n",
    "print(predictions)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline = ModelPipeline(data=data, objective='Depression (%)',model_type='RF')\n",
    "model, scaler, predictions, mse = pipline.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "StandardScaler()\n",
      "None\n",
      "5.665777512891743e-05\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(scaler)\n",
    "print(predictions)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
