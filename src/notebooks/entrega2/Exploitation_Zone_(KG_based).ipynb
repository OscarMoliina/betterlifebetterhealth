{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploitation Zone (KG-based)**"
      ],
      "metadata": {
        "id": "IN2-9ntcwbUx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGPP1ZgLgu_A",
        "outputId": "87d985a2-5613-4195-d5b3-a2b54dd3cadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'betterlifebetterhealth'...\n",
            "remote: Enumerating objects: 342, done.\u001b[K\n",
            "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
            "remote: Compressing objects: 100% (152/152), done.\u001b[K\n",
            "remote: Total 342 (delta 58), reused 124 (delta 35), pack-reused 155\u001b[K\n",
            "Receiving objects: 100% (342/342), 100.31 MiB | 16.11 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OscarMoliina/betterlifebetterhealth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install pyspark\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col, mean, when, lit, count\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import mean\n",
        "from pyspark.sql.functions import mean\n",
        "from pyspark.sql.types import IntegerType, DoubleType\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import collect_list\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import duckdb"
      ],
      "metadata": {
        "id": "Gt1wtnMQhNUL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Preprocessing\") \\\n",
        "    .config(\"spark.jars\", \"/content/betterlifebetterhealth/src/utils/duckdb.jar\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "join = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:duckdb:/content/betterlifebetterhealth/data/db/exploitation_zone.db\") \\\n",
        "    .option(\"driver\", \"org.duckdb.DuckDBDriver\") \\\n",
        "    .option(\"dbtable\", \"join_table\") \\\n",
        "    .load()"
      ],
      "metadata": {
        "id": "I1xphyO6hQ2Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Classificació dels països per regió:**\n",
        "Afegim relació per dividir Europa en 4 zones: Europa del Este, Europa del Sur, Europa Occidental y Europa del Norte.\n",
        "\n",
        "1. Europa del Nord: Suècia, Finlàndia, Noruega, Dinamarca, Islàndia, Estònia, Letònia, Lituània\n",
        "2. Europa de l'Est: Polònia, Eslovàquia, República Txeca, Hongria, Romania, Bulgària, Bielorússia, Ucraïna, Moldàvia, Rússia, Albània, Kosovo, Macedònia del Nord, Montenegro, Sèrbia, Bòsnia i Hercegovina\n",
        "3. Europa del Sud: Itàlia, Espanya, Portugal, Grècia, Turquia, Xipre, Malta, Croàcia, Eslovènia\n",
        "4. Europa Occidental: Alemanya, França, Bèlgica, Països Baixos, Àustria, Suïssa, Luxemburg, Regne Unit, Irlanda"
      ],
      "metadata": {
        "id": "OxSKEtDAlwqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de países por región incluyendo Asia\n",
        "north_europe = ['Sweden', 'Finland', 'Norway', 'Denmark', 'Iceland', 'Estonia', 'Latvia', 'Lithuania']\n",
        "east_europe = ['Poland', 'Slovakia', 'Hungary', 'Romania', 'Bulgaria', 'Belarus', 'Ukraine', 'Albania', 'Moldova', 'Czech Republic', 'Russia', 'North Macedonia', 'Montenegro', 'Serbia', 'Bosnia and Herzegovina']\n",
        "south_europe = ['Italy', 'Spain', 'Portugal', 'Greece', 'Cyprus', 'Malta', 'Croatia', 'Slovenia']\n",
        "west_europe = ['Germany', 'France', 'Belgium', 'Netherlands', 'Austria', 'Switzerland', 'Luxembourg', 'United Kingdom', 'Ireland']\n",
        "asia = ['Turkey', 'Israel', 'Georgia', 'Azerbaijan', 'Armenia', 'Kazakhstan', 'Uzbekistan', 'Turkmenistan', 'Tajikistan', 'Kyrgyzstan']\n",
        "\n",
        "# Función para asignar la región basada en el país\n",
        "def assign_region(country):\n",
        "    if country in north_europe:\n",
        "        return 'Europe North'\n",
        "    elif country in east_europe:\n",
        "        return 'Europe East'\n",
        "    elif country in south_europe:\n",
        "        return 'Europe South'\n",
        "    elif country in west_europe:\n",
        "        return 'Europe West'\n",
        "    elif country in asia:\n",
        "        return 'Asia'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "region_udf = udf(assign_region, StringType())\n",
        "\n",
        "# Crear una nueva columna con la región asignada\n",
        "join = join.withColumn('Region', region_udf(join['Country']))"
      ],
      "metadata": {
        "id": "L_cGB6sPl2Ps"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pertanyença a UE:**\n",
        "Afegim relació per distingir els que pertanyen a la Unió Europea i els que no."
      ],
      "metadata": {
        "id": "4PL8lsJVntCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eu_countries = [\n",
        "    'Austria', 'Belgium', 'Bulgaria', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark',\n",
        "    'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Ireland', 'Italy',\n",
        "    'Latvia', 'Lithuania', 'Luxembourg', 'Malta', 'Netherlands', 'Poland', 'Portugal',\n",
        "    'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Sweden'\n",
        "]\n",
        "\n",
        "# Función para determinar la membresía en la UE\n",
        "def is_eu_member(country):\n",
        "    return 'EU Member' if country in eu_countries else 'Non-EU Member'\n",
        "\n",
        "# UDF para aplicar la función en Spark\n",
        "eu_member_udf = udf(is_eu_member, StringType())\n",
        "\n",
        "join = join.withColumn('EU Membership', eu_member_udf(join['Country']))\n"
      ],
      "metadata": {
        "id": "ILFbxnGDnytA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pertanyença a NATO:**\n",
        "\n"
      ],
      "metadata": {
        "id": "tR6_IeMaoW-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de países miembros de la OTAN\n",
        "nato_countries = [\n",
        "    'Albania', 'Belgium', 'Bulgaria', 'Canada', 'Croatia', 'Czech Republic', 'Denmark',\n",
        "    'Estonia', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Italy', 'Latvia',\n",
        "    'Lithuania', 'Luxembourg', 'Montenegro', 'Netherlands', 'North Macedonia', 'Norway',\n",
        "    'Poland', 'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Turkey', 'United Kingdom', 'United States'\n",
        "]\n",
        "\n",
        "# Función para determinar la membresía en la OTAN\n",
        "def is_nato_member(country):\n",
        "    return 'NATO Member' if country in nato_countries else 'Non-NATO Member'\n",
        "\n",
        "# UDF para aplicar la función en Spark\n",
        "nato_member_udf = udf(is_nato_member, StringType())\n",
        "\n",
        "join = join.withColumn('NATO Membership', nato_member_udf(join['Country']))\n"
      ],
      "metadata": {
        "id": "6Fhrwg64oqMo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Països que fan frontera:**"
      ],
      "metadata": {
        "id": "IV3vfczmwyl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fronteres = spark.read.option(\"header\", \"true\").csv('/content/betterlifebetterhealth/data/csv/GEODATASOURCE-COUNTRY-BORDERS.CSV')"
      ],
      "metadata": {
        "id": "rbdZvhNPw9Oi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "borders_grouped = fronteres.groupBy(\"country_name\").agg(collect_list(\"country_border_name\").alias(\"border_countries\"))"
      ],
      "metadata": {
        "id": "pwvE1VBQyGPI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join = join.join(borders_grouped, join['Country'] == borders_grouped['country_name'], 'left')"
      ],
      "metadata": {
        "id": "G9zeuwyOza18"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join = join.drop(\"country_name\")"
      ],
      "metadata": {
        "id": "L5gPNxKg0ogr"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}